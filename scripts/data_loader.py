# scripts/data_loader.py

# --- 1. IMPORTA√á√ïES ---
import streamlit as st
import pandas as pd
import pickle
import requests
import os
import time
from typing import Dict, Any, Tuple, Set

# --- 2. CONFIGURA√á√ïES GLOBAIS ---
DATA_PATH = 'dados/ml-32m/ratings.csv'
# URL de download direto para o modelo pr√©-treinado (hospedado no Google Drive)
MODEL_URL = 'https://drive.google.com/uc?export=download&id=18S57U_3Pic74oFef-2QjwkbuvjUFEYXe'
# Nome do arquivo do modelo como ser√° salvo localmente na raiz do projeto
MODEL_PATH = 'svd_model_data.pkl'


# ==========================================================
#   FUN√á√ÉO: DOWNLOAD DO MODELO
# ==========================================================
# @st.cache_data garante que o download s√≥ aconte√ßa uma vez.
# Se o arquivo j√° foi baixado, o Streamlit n√£o executa a fun√ß√£o novamente.
@st.cache_data
def download_model(url: str, filepath: str) -> None:
    """
    Verifica se o arquivo do modelo existe localmente. Se n√£o, faz o download
    de uma URL, exibindo uma barra de progresso detalhada com velocidade e ETA.
    """

    # Verifica se o arquivo j√° existe para evitar downloads desnecess√°rios
    if os.path.exists(filepath):
        file_size_mb = os.path.getsize(filepath) / (1024 * 1024)
        st.info(f"‚úÖ Modelo encontrado localmente ({file_size_mb:.1f} MB).")
        return # Encerra a fun√ß√£o se o arquivo j√° existe

    st.warning(f"üì¶ Modelo '{filepath}' n√£o encontrado. Iniciando download (~1.9 GB)...")

    try:
        # Inicia o download usando requests com stream=True, essencial para arquivos grandes,
        # pois n√£o carrega todo o conte√∫do na mem√≥ria de uma vez.
        with requests.get(url, stream=True, timeout=60) as r:
            r.raise_for_status() # Garante que a resposta foi bem-sucedida (c√≥digo 200)

            # Pega o tamanho total do arquivo do cabe√ßalho da resposta para a barra de progresso
            total_size = int(r.headers.get('content-length', 0))
            bytes_downloaded = 0
            block_size = 1024 * 1024  # Define peda√ßos de 1 MB para o download

            # Prepara os elementos da UI do Streamlit que ser√£o atualizados dinamicamente
            progress_bar = st.progress(0)
            progress_text = st.empty()
            start_time = time.time()

            # Abre o arquivo local em modo de "escrita bin√°ria" ('wb') para salvar os dados
            with open(filepath, 'wb') as f:
                # Itera sobre o download em peda√ßos (chunks)
                for chunk in r.iter_content(chunk_size=block_size):
                    if chunk: # Filtra chunks de "keep-alive" que podem vir vazios
                        f.write(chunk)
                        bytes_downloaded += len(chunk)

                        # Apenas calcula e exibe as m√©tricas se o download for grande o suficiente
                        if total_size and (time.time() - start_time) > 0.5:
                            progress = bytes_downloaded / total_size
                            elapsed = time.time() - start_time
                            speed = bytes_downloaded / (1024 * 1024 * elapsed)
                            remaining_time = (total_size - bytes_downloaded) / (speed * 1024 * 1024) if speed > 0 else 0

                            # Atualiza a barra de progresso e o texto com as m√©tricas
                            progress_text.markdown(
                                f"‚¨áÔ∏è **Baixando modelo...** "
                                f"{bytes_downloaded/1024/1024:.1f} / {total_size/1024/1024:.1f} MB "
                                f"(`{speed:.2f} MB/s`, tempo restante: {remaining_time:.0f}s)"
                            )
                            progress_bar.progress(min(1.0, progress))

        # Limpa os elementos da UI ap√≥s o download ser conclu√≠do
        progress_bar.empty()
        progress_text.empty()
        st.success("‚úÖ Download conclu√≠do!")

    except Exception as e:
        # Em caso de erro durante o download, remove o arquivo parcial para evitar corrup√ß√£o
        if os.path.exists(filepath):
            os.remove(filepath)
        st.error(f"‚ùå Erro fatal ao baixar o modelo: {e}")
        st.stop() # Interrompe a execu√ß√£o do app se o modelo n√£o puder ser baixado


# ==========================================================
#   FUN√á√ÉO: CARREGAMENTO PRINCIPAL
# ==========================================================
# @st.cache_resource executa esta fun√ß√£o inteira apenas UMA VEZ.
# show_spinner=False desativa o spinner gen√©rico, pois temos os nossos customizados.
@st.cache_resource(show_spinner=False)
def load_model_and_data() -> Tuple[Any, Tuple[Dict[str, Set[str]], Set[str]], Tuple[Dict[str, str], Dict[str, str]], int]:
    """
    Orquestra todo o processo de carga: download do modelo, leitura dos dados
    e prepara√ß√£o das estruturas de dados otimizadas para a recomenda√ß√£o.
    """

    # --- 1. Garante que o modelo est√° dispon√≠vel localmente ---
    download_model(MODEL_URL, MODEL_PATH)

    # --- 2. Carrega o modelo do arquivo .pkl para a mem√≥ria ---
    with st.spinner("üß† Carregando modelo de recomenda√ß√£o..."):
        with open(MODEL_PATH, 'rb') as f:
            model_data = pickle.load(f)

    # Desempacota os objetos do dicion√°rio salvo
    model_svd = model_data['model']
    id_to_titulo = model_data['id_to_titulo']
    id_to_generos = model_data['id_to_generos']

    # --- 3. Leitura e processamento da base de avalia√ß√µes ---
    with st.spinner(f"üìä Lendo e processando a base de avalia√ß√µes..."):
        ratings_df = pd.read_csv(DATA_PATH)
        ratings_df.columns = ['user_id', 'item_id', 'rating', 'timestamp']
        ratings_df['user_id'] = ratings_df['user_id'].astype(str)
        ratings_df['item_id'] = ratings_df['item_id'].astype(str)
        max_user_id = int(ratings_df['user_id'].astype(int).max())

    # --- 4. Constru√ß√£o de estruturas otimizadas para performance ---
    with st.spinner("üîß Preparando o motor de recomenda√ß√£o..."):
        # Cria um dicion√°rio: {user_id: {item_id_1, item_id_2, ...}}
        # Este m√©todo (itertuples) √© otimizado para baixo consumo de mem√≥ria.
        user_rated_items = {}
        for row in ratings_df[['user_id', 'item_id']].itertuples(index=False):
            user_rated_items.setdefault(row.user_id, set()).add(row.item_id)
        
        # Cria um conjunto com todos os IDs de itens √∫nicos para a l√≥gica de previs√£o
        all_item_ids = set(ratings_df['item_id'].unique())

    st.success("üöÄ Modelo e dados prontos para uso!")

    # Agrupa os objetos de retorno para uma sa√≠da mais limpa da fun√ß√£o
    opt_data = (user_rated_items, all_item_ids)
    maps = (id_to_titulo, id_to_generos)
    
    return model_svd, opt_data, maps, max_user_id
